---
layout: post
title:  How to fetch Twitter users with R
date: "2017-04-20 12:11:29 UYT"
published: true
tags: [rstats, r, Twitter, rtweet, purrr, map, ggmap]
description: How to fetch Twitter users and clean the data using R!
---
Here I show how to fetch Twitter users using the `rtweet` package, and clean the data using the `tidyverse` set of packages, for later usage in plotting animated maps.  

<!--more-->

Recently [I came across this post](http://spatial.ly/2017/03/mapping-5000-years-of-city-growth/), and I knew I had to make a similar map for the [R-Ladies' chapters](http://rladies.org/) (probably the purple color had plenty to do with that `r emo::ji("purple_heart")` ). So my idea was to map all the R-Ladies' chapters according to their size, and that's when I thought of using their Twitter followers as a way to estimate it, since it's the social media we use by excelence (except for some specific chapters).  

If I wanted to show everything I've done in a single post, it would be almost as long as my first one! And I didn't want that `r emo::ji("stuck_out_tongue_closed_eyes")` . So I decided to make 2 _tutorial-like_ posts: one for the data preparation (this very one), and the second one about making the maps and animating them. And finally other post where I just go through what I did without getting into too many details, focusing on the visualisation results. 

So here I go!

# Getting Twitter users

I had to learn how to retrieve data from the Twitter API, and I chose to use the `rtweet` package, which is super easy to use! 

Every R-Ladies' chapter uses a standard handle, using the *RLadiesLocation* format (thankfully they are very compliant with this!). By setting the `q` parameter to `'RLadies'` I'm setting the query to be searched. `n = 1000` sets the amount of users to retrieve, being 1000 the maximum number of users returned from a single search. As I want a dataframe as a result, I set the `parse` parameter to `TRUE`.

Since I only use public data I don't have to worry about getting my Twitter personal access token (for now at least).

```{r load_data, echo = FALSE, message = FALSE, warning = FALSE}
# The data isn't in this repository, you can find everything I use here:
# https://github.com/d4tagirl/R-Ladies-growth-maps

library(knitr)
knitr::opts_chunk$set(dpi = 130, fig.align = 'center', screenshot.force = FALSE, fig.cap = "")
options(width = 80, dplyr.width = 150)

# users <- readRDS(gzcon(url('https://github.com/d4tagirl/R-Ladies-growth-maps/raw/master/users.rds')))

library(readr)
library(dplyr)
users <- read_csv(url('https://raw.githubusercontent.com/d4tagirl/R-Ladies-growth-maps/master/users.csv')) %>% 
  select(-1)

```

```{r  false_load_data, eval = FALSE}
library(rtweet)

users <- search_users(q = 'RLadies',
                      n = 1000,
                      parse = TRUE)
```

Let's see what it returns:

```{r message = FALSE, warning = FALSE}
library(DT)
datatable(users[, c(2:5)], rownames = FALSE,
          options = list(pageLength = 5))
```

<br/>
This is great! It retrieves the user if it matches the user's _description_ as well as _name_ and _screen\_name_ (handle), with 36 variables regarding the user. I'm only showing the ones I'm going to use, but there is a lot of extra information there.

I used `DT::datatable` just in case someone wants to go through whats on the whole table (of course here I'm thinking about the R-Ladies community). It was not easy to set up the environment for my blog to show this table (it uses `HTML widgets`), but luckily my hubby was more than willing to help me with that part `r emo::ji("sweat_smile")` . If you are using RStudio it is just as simple as installing the `DT` package, or you can always use `knitr::kable(head(users[, c(2:5)]), format = "html")` to see the first rows.

# Cleaning the data

First I make sure I don't have any duplicates, and then I keep only the handles that comply with the stipulated format, using a regular expression. I filter out 3 additional handles: _'RLadies'_ (whose _name_ is _'Royal Ladies'_ and I assume has something to do with royalty by the crown on their picture), _'RLadies\_LF'_ (a Japanese account that translated as follows on _Google Translator_: _'Rakuten Ichiba fashion delivery'_), and _'RLadiesGlobal'_, because it is not a chapter, so I don't want to include it on the plot. 

I also correct the missing values on `location` that I'll need to geocode the chapters, format the date class variable `created_at` as `%Y-%m-%d` (just because seeing the hours, minutes and seconds annoys me!) and generate the age in days `age_days` (for reproducibility, I set a fixed date to compare it with).

Finally I select the variables I will use for my analysis.

So it's time to clean up this data:

```{r  head_rladies, message = FALSE, warning = FALSE}
library(dplyr)
library(lubridate)
library(stringr)
library(tidyr)

rladies <- unique(users) %>%
  filter(str_detect(screen_name, '^(RLadies).*') & 
           !screen_name %in% c('RLadies', 'RLadies_LF', 'RLadiesGlobal')) %>% 
  mutate(location = ifelse(screen_name == 'RLadiesLx', 'Lisbon',
                         ifelse(screen_name == 'RLadiesMTL', 'Montreal', location)),
         created_at = format(as.Date(created_at), format = '%Y-%m-%d'),
         age_days = difftime(as.Date('2017-4-25'), created_at, unit = 'days')) %>%
  select(screen_name, location, created_at, followers = followers_count, age_days)
```

There are two additional chapters with no presence on Twitter: one in Taipei, Taiwan, and the other in Warsaw, Poland. I add them according to their creation date and using the number of members on their Meetup account as followers.

```{r  message = FALSE, warning = FALSE}

rladies <- rladies %>% 
  add_row(      
    screen_name = 'RLadiesTaipei',
    location = 'Taipei',
    created_at = as.Date('2014-11-15'),
    followers = 347) %>% 
  add_row(      
    screen_name = 'RLadiesWarsaw',
    location = 'Warsaw',
    created_at = as.Date('2016-11-15'),
    followers = 80)

datatable(rladies, rownames = FALSE,
          options = list(pageLength = 5))
```

<br />
As my ultimate goal is to plot the chapters on a map, I need to obtain the latitude and longitude for each one of them. The `ggmap` package really comes in handy for this kind of task. It interacts with _Google Maps_ to retrieve latitude and longitude, and I don't even have to worry about getting the location into a specific format, because it is so good at interpreting it! (I actually tried extracting the cities first, because I thought it would be the best way, but many of the chapters didn't match or matched wrongly, so I tried it like that and worked perfectly!)

Since the `ggmap::geocode` function returns 2 columns, the first thing I thought was to call it twice: once for the longitude and once for the latitude. But I didn't like it because it was awfully inefficient, and the geocoding takes some time. It was going to be something like this:

```{r  false2, eval = FALSE}
library(ggmap)

rladies <- rladies %>% 
  mutate(lon = geocode(location)[,1],
         lat = geocode(location)[,2])
```

Doing some research I finally decided to use the `purrr::map` function for capturing both values in a single column of the dataframe, and then with `tidyr::unnest` I transform it into two separate columns. All of this with never having to leave the `tidyverse` world :)

I'm doing it in two steps to see the intermediate result, with the two columns in a single variable of the dataframe.

```{r  false3, eval = FALSE}

library(ggmap)
library(purrr)

rladies <- rladies %>% 
  mutate(longlat = purrr::map(.$location, geocode)) 

datatable(rladies, rownames = FALSE,
          options = list(pageLength = 5))   
```

```{r echo = FALSE, message = FALSE, warning = FALSE, screenshot.force = FALSE}

# rladies <- readRDS(gzcon(url('https://github.com/d4tagirl/R-Ladies-growth-maps/raw/master/rladies_longlat.rds')))

kable(head(rladies), format = "html")
```

```{r}
rladies <- rladies %>% 
  unnest() 

datatable(rladies, rownames = FALSE,
          options = list(pageLength = 5))        
```

<br />
That's it!

Now the dataframe is ready for me to use it for visualizing these Twitter users on a map (considering their sizes and dates of creation), and make some animations! If you are interested, you can check how I do it [here for using `plotly`](){:target="_blank"} and [here for using `gganimate`](){:target="_blank"}.

Thank you for reading! Please leave your comments and suggestions below or [Mention me on Twitter](https://twitter.com/intent/tweet?user_id=114258616) :)
